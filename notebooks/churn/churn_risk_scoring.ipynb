{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a894edf-18c0-4181-a1a6-c4ef876955f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.special import expit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5382f461-cb34-469d-926a-7f0da3bc109a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_FILE_PATH = \"../../data/raw/robot_churn_poc_dataset.csv\"\n",
    "TARGET_FILE_PATH = \"../../data/curated/churn_risk_scores.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f69dd3d6-eb99-4502-872a-758906258674",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(SOURCE_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e2f9ab1-305d-4f56-8f84-05eb79de51b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"churn_flag_next_6m\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48237ca-0ef5-4fc4-984d-0ef356b16e63",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "719c14af-f536-40d2-808f-0d12469fb2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rolling_average(\n",
    "    df: pd.DataFrame,\n",
    "    column: str,\n",
    "    window: int,\n",
    "    group_cols=(\"customer_id\", \"site_id\"),\n",
    "    time_col=\"year_month\",\n",
    "    min_periods=1\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate rolling average for a given column grouped by customer/site.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Input dataframe.\n",
    "    column : str\n",
    "        Column name to calculate rolling average for.\n",
    "    window : int\n",
    "        Rolling window size (number of months).\n",
    "    group_cols : tuple\n",
    "        Columns used to group the rolling calculation.\n",
    "    time_col : str\n",
    "        Time column (must be sortable).\n",
    "    min_periods : int\n",
    "        Minimum periods required for calculation.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        DataFrame with a new rolling average column appended.\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    # Ensure proper datetime sorting\n",
    "    df[time_col] = pd.to_datetime(df[time_col])\n",
    "\n",
    "    df = df.sort_values(list(group_cols) + [time_col])\n",
    "\n",
    "    rolling_col_name = f\"{column}_rolling_avg_{window}m\"\n",
    "\n",
    "    df[rolling_col_name] = (\n",
    "        df\n",
    "        .groupby(list(group_cols))[column]\n",
    "        .transform(lambda x: x.rolling(window=window, min_periods=min_periods).mean())\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edf35220-7208-49a4-8250-c7348abed41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_trend_slope(\n",
    "    df: pd.DataFrame,\n",
    "    column: str,\n",
    "    window: int,\n",
    "    group_cols=(\"customer_id\", \"site_id\"),\n",
    "    time_col=\"year_month\",\n",
    "    min_periods=2\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate rolling trend slope (linear regression slope) for a given column.\n",
    "    The slope represents direction:\n",
    "        > 0  -> increasing trend\n",
    "        < 0  -> decreasing trend\n",
    "        ~ 0  -> stable\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Input dataframe.\n",
    "    column : str\n",
    "        Column to calculate slope for.\n",
    "    window : int\n",
    "        Rolling window size (number of months).\n",
    "    group_cols : tuple\n",
    "        Columns used for grouping.\n",
    "    time_col : str\n",
    "        Time column (must be sortable).\n",
    "    min_periods : int\n",
    "        Minimum number of periods required to compute slope.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        DataFrame with new slope column appended.\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    df[time_col] = pd.to_datetime(df[time_col])\n",
    "    df = df.sort_values(list(group_cols) + [time_col])\n",
    "\n",
    "    slope_col_name = f\"{column}_slope_{window}m\"\n",
    "\n",
    "    def rolling_slope(series):\n",
    "        y = series.values\n",
    "        x = np.arange(len(y))\n",
    "\n",
    "        if len(y) < min_periods:\n",
    "            return np.nan\n",
    "\n",
    "        # Linear regression slope (least squares)\n",
    "        slope = np.polyfit(x, y, 1)[0]\n",
    "        return slope\n",
    "\n",
    "    df[slope_col_name] = (\n",
    "        df\n",
    "        .groupby(list(group_cols))[column]\n",
    "        .transform(\n",
    "            lambda x: x.rolling(window=window, min_periods=min_periods)\n",
    "                      .apply(rolling_slope, raw=False)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74d13a76-05ba-4fa0-9b0e-6af7bc697c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_consecutive_movement(\n",
    "    df: pd.DataFrame,\n",
    "    column: str,\n",
    "    group_cols=(\"customer_id\", \"site_id\"),\n",
    "    time_col=\"year_month\"\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate consecutive upward and downward movements for a numeric column.\n",
    "\n",
    "    Creates the following columns:\n",
    "        - <column>_diff\n",
    "        - <column>_direction  (1=up, -1=down, 0=no change)\n",
    "        - <column>_consec_up\n",
    "        - <column>_consec_down\n",
    "\n",
    "    Example:\n",
    "        3 months consecutive NPS drop → consec_down = 3\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.copy()\n",
    "    df[time_col] = pd.to_datetime(df[time_col])\n",
    "    df = df.sort_values(list(group_cols) + [time_col])\n",
    "\n",
    "    diff_col = f\"{column}_diff\"\n",
    "    dir_col = f\"{column}_direction\"\n",
    "    up_col = f\"{column}_consec_up\"\n",
    "    down_col = f\"{column}_consec_down\"\n",
    "\n",
    "    # Month-over-month difference\n",
    "    df[diff_col] = (\n",
    "        df.groupby(list(group_cols))[column]\n",
    "          .diff()\n",
    "    )\n",
    "\n",
    "    # Direction: 1 up, -1 down, 0 stable\n",
    "    df[dir_col] = np.sign(df[diff_col]).fillna(0)\n",
    "\n",
    "    def compute_streak(series, direction_value):\n",
    "        streak = []\n",
    "        counter = 0\n",
    "        for val in series:\n",
    "            if val == direction_value:\n",
    "                counter += 1\n",
    "            else:\n",
    "                counter = 0\n",
    "            streak.append(counter)\n",
    "        return streak\n",
    "\n",
    "    df[up_col] = (\n",
    "        df.groupby(list(group_cols))[dir_col]\n",
    "          .transform(lambda x: compute_streak(x, 1))\n",
    "    )\n",
    "\n",
    "    df[down_col] = (\n",
    "        df.groupby(list(group_cols))[dir_col]\n",
    "          .transform(lambda x: compute_streak(x, -1))\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d35365d1-223f-4f6e-bef5-f7cc66de7495",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_behavior_deterioration_score(\n",
    "    df: pd.DataFrame,\n",
    "    features: list,\n",
    "    window: int = 3,\n",
    "    group_cols=(\"customer_id\", \"site_id\"),\n",
    "    time_col=\"year_month\"\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create unified deterioration score combining:\n",
    "    - slope\n",
    "    - consecutive streak\n",
    "    - deviation vs rolling average\n",
    "\n",
    "    Returns dataframe with:\n",
    "        behavior_deterioration_score\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.copy()\n",
    "    df[time_col] = pd.to_datetime(df[time_col])\n",
    "    df = df.sort_values(list(group_cols) + [time_col])\n",
    "\n",
    "    deterioration_components = []\n",
    "\n",
    "    for col in features:\n",
    "\n",
    "        slope_col = f\"{col}_slope_{window}m\"\n",
    "        streak_down_col = f\"{col}_consec_down\"\n",
    "        streak_up_col = f\"{col}_consec_up\"\n",
    "        rolling_col = f\"{col}_rolling_avg_{window}m\"\n",
    "\n",
    "        # --- Slope Component ---\n",
    "        slope_component = -df[slope_col]  # negative slope = deterioration\n",
    "\n",
    "        # --- Streak Component ---\n",
    "        # For positive performance metrics → down streak is bad\n",
    "        if col not in [\"upgrade_failures\", \"lack_of_rca\"]:\n",
    "            streak_component = df[streak_down_col]\n",
    "        else:\n",
    "            # For failure metrics → up streak is bad\n",
    "            streak_component = df[streak_up_col]\n",
    "\n",
    "        # --- Rolling Deviation Component ---\n",
    "        deviation = df[col] - df[rolling_col]\n",
    "\n",
    "        if col not in [\"upgrade_failures\", \"lack_of_rca\"]:\n",
    "            deviation_component = -deviation  # below avg = bad\n",
    "        else:\n",
    "            deviation_component = deviation   # above avg = bad\n",
    "\n",
    "        # Normalize each component\n",
    "        for comp in [slope_component, streak_component, deviation_component]:\n",
    "            comp_norm = (comp - comp.mean()) / (comp.std() + 1e-6)\n",
    "            deterioration_components.append(comp_norm)\n",
    "\n",
    "    # Aggregate all components\n",
    "    df[\"behavior_deterioration_score\"] = np.mean(deterioration_components, axis=0)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5017c39-f3af-4dca-9839-1f894fe7bdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    \"usage_volume\",\n",
    "    \"bot_utilization\",\n",
    "    \"bot_performance\",\n",
    "    \"associate_performance\",\n",
    "    \"bot_uptime\",\n",
    "    \"upgrade_failures\",\n",
    "    \"support_sla\",\n",
    "    \"lack_of_rca\",\n",
    "    \"nps\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a884c4e-7086-4e60-b919-6296818e6bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in features:\n",
    "    df = calculate_rolling_average(df, feature, window=3)\n",
    "\n",
    "for feature in features:\n",
    "    df = calculate_trend_slope(df, feature, window=3)\n",
    "\n",
    "for feature in features:\n",
    "    df = calculate_consecutive_movement(df, feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c8d69ed-2497-4def-824e-3c2b725b0bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = calculate_behavior_deterioration_score(\n",
    "    df,\n",
    "    features=features,\n",
    "    window=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a3fb4ad-fe30-40c9-8e24-ae166f8d3624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance deterioration (3 consecutive drops)\n",
    "df[\"nps_3m_drop_flag\"] = df[\"nps_consec_down\"] >= 3\n",
    "df[\"usage_3m_drop_flag\"] = df[\"usage_volume_consec_down\"] >= 3\n",
    "df[\"utilization_3m_drop_flag\"] = df[\"bot_utilization_consec_down\"] >= 3\n",
    "df[\"performance_3m_drop_flag\"] = df[\"bot_performance_consec_down\"] >= 3\n",
    "df[\"uptime_2m_drop_flag\"] = df[\"bot_uptime_consec_down\"] >= 2\n",
    "df[\"sla_2m_drop_flag\"] = df[\"support_sla_consec_down\"] >= 2\n",
    "\n",
    "# Operational issue escalation (2+ consecutive increases)\n",
    "df[\"failures_2m_rise_flag\"] = df[\"upgrade_failures_consec_up\"] >= 2\n",
    "df[\"rca_2m_rise_flag\"] = df[\"lack_of_rca_consec_up\"] >= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e630956-d66d-47ea-aa77-512b63715935",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_streaks = [\n",
    "    \"usage_volume_consec_down\",\n",
    "    \"bot_utilization_consec_down\",\n",
    "    \"bot_performance_consec_down\",\n",
    "    \"associate_performance_consec_down\",\n",
    "    \"bot_uptime_consec_down\",\n",
    "    \"support_sla_consec_down\",\n",
    "    \"nps_consec_down\"\n",
    "]\n",
    "\n",
    "failure_streaks = [\n",
    "    \"upgrade_failures_consec_up\",\n",
    "    \"lack_of_rca_consec_up\"\n",
    "]\n",
    "\n",
    "df[\"streak_risk_score\"] = (\n",
    "    df[performance_streaks].sum(axis=1) +\n",
    "    df[failure_streaks].sum(axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9d04979-7423-42e2-aead-5381a623d688",
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_df = (\n",
    "    df.sort_values(\"year_month\")\n",
    "        .groupby([\"customer_id\", \"site_id\"], as_index=False)\n",
    "        .tail(1)\n",
    "        .copy()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8862b2ad-bff7-490b-af29-fa6e3546737e",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = latest_df[\"behavior_deterioration_score\"]\n",
    "latest_df[\"score_z\"] = (score - score.mean()) / (score.std() + 1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60b78e54-09e1-4d77-afb4-6e95b2756cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1.5\n",
    "latest_df[\"calibrated_probability\"] = expit(alpha * latest_df[\"score_z\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2f93c8f-6d34-4004-be03-daa026d4430d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_to_risk(p: float) -> str:\n",
    "    if p < 0.40:\n",
    "        return \"low\"\n",
    "    elif p < 0.70:\n",
    "        return \"medium\"\n",
    "    return \"high\"\n",
    "\n",
    "latest_df[\"churn_risk\"] = latest_df[\"calibrated_probability\"].apply(prob_to_risk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e89ee371-22ca-4296-90d0-e7c53da0cd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_df[\"calibrated_probability\"] = latest_df[\"calibrated_probability\"].map(lambda x: f\"{x:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f6df3bed-e8fd-427e-b121-9c8cf82aad77",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = (\n",
    "    latest_df[\n",
    "        [\n",
    "            \"customer_id\",\n",
    "            \"site_id\",\n",
    "            \"year_month\",\n",
    "            \"churn_risk\",\n",
    "            \"calibrated_probability\",\n",
    "            \"behavior_deterioration_score\",\n",
    "            \"usage_volume\",\n",
    "            \"bot_utilization\",\n",
    "            \"bot_performance\",\n",
    "            \"bot_uptime\",\n",
    "            \"support_sla\",\n",
    "            \"nps\",\n",
    "            \"usage_volume_slope_3m\",\n",
    "            \"bot_performance_slope_3m\",\n",
    "            \"bot_uptime_slope_3m\",\n",
    "            \"support_sla_slope_3m\",\n",
    "            \"nps_slope_3m\",\n",
    "            \"nps_consec_down\",\n",
    "            \"usage_volume_consec_down\",\n",
    "            \"upgrade_failures_consec_up\",\n",
    "            \"lack_of_rca_consec_up\"\n",
    "        ]\n",
    "    ]\n",
    "    .sort_values([\"customer_id\", \"site_id\"])\n",
    "    .reset_index(drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7790367-bdd6-4e6b-b4d9-c3d0913a268d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "969d417f-67a1-4de9-a495-f7051791f780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "churn_risk\n",
       "low       0.450980\n",
       "high      0.294118\n",
       "medium    0.254902\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df[\"churn_risk\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24e71f0-f8d9-4aaa-8b9c-8053fc098aba",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b4561283-9eba-4b0e-84cf-0139db1f0cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df.to_csv(TARGET_FILE_PATH, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
